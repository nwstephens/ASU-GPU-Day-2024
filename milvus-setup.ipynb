{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use bulkInsert to test GPU index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Docker installation: https://docs.docker.com/engine/install/ubuntu/\n",
    "2. Install nvidia-docker2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -\n",
    "distribution=$(. /etc/os-release;echo $ID$VERSION_ID)\n",
    "curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list\n",
    "sudo apt-get update\n",
    "sudo apt-get install nvidia-docker2\n",
    "sudo systemctl restart docker.service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Install NVIDIA driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo apt install --no-install-recommends  nvidia-headless-535 nvidia-utils-535"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (Optional) mount a high performance disk for test. We need to ensure all following operations are in a high performance disk. For an AWS host, we need to manually mount the NVMe SSD (For example, g4dn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsblk # see device path\n",
    "sudo mkfs -t ext4 /dev/nvme1n1\n",
    "sudo mkdir /data\n",
    "sudo mount /dev/nvme1n1 /data\n",
    "sudo -i blkid # get /dev/nvme1n1 UUID, e.g. dd04113f-deb6-42b0-a021-03110c119295 \n",
    "sudo vi /etc/fstab # add to the tail: UUID=<UUID get from previous cmd> /data ext4 defaults 1 2\n",
    "cd /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download milvus image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo docker pull milvusdb/milvus:v2.4.0-rc.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use docker compose to start the milvus service "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the following file as docker-compose.yml."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "version: '3.5'\n",
    "\n",
    "services:\n",
    "  etcd:\n",
    "    container_name: milvus-etcd\n",
    "    image: quay.io/coreos/etcd:v3.5.5\n",
    "    environment:\n",
    "      - ETCD_AUTO_COMPACTION_MODE=revision\n",
    "      - ETCD_AUTO_COMPACTION_RETENTION=1000\n",
    "      - ETCD_QUOTA_BACKEND_BYTES=4294967296\n",
    "      - ETCD_SNAPSHOT_COUNT=50000\n",
    "    volumes:\n",
    "      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/etcd:/etcd\n",
    "    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"etcdctl\", \"endpoint\", \"health\"]\n",
    "\n",
    "  minio:\n",
    "    container_name: milvus-minio\n",
    "    image: minio/minio:RELEASE.2023-03-20T20-16-18Z\n",
    "    environment:\n",
    "      MINIO_ACCESS_KEY: minioadmin\n",
    "      MINIO_SECRET_KEY: minioadmin\n",
    "    ports:\n",
    "      - \"9001:9001\"\n",
    "      - \"9000:9000\"\n",
    "    volumes:\n",
    "      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/minio:/minio_data\n",
    "    command: minio server /minio_data --console-address \":9001\"\n",
    "    healthcheck:\n",
    "      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:9000/minio/health/live\"]\n",
    "      interval: 30s\n",
    "      timeout: 20s\n",
    "      retries: 3\n",
    "\n",
    "  standalone:\n",
    "    container_name: milvus-standalone\n",
    "    image: milvusdb/milvus:v2.4.0.1-gpu-beta\n",
    "    command: [\"milvus\", \"run\", \"standalone\"]\n",
    "    environment:\n",
    "      ETCD_ENDPOINTS: etcd:2379\n",
    "      MINIO_ADDRESS: minio:9000\n",
    "    volumes:\n",
    "      - ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus\n",
    "    ports:\n",
    "      - \"19530:19530\"\n",
    "      - \"9091:9091\"\n",
    "    deploy:\n",
    "      resources:\n",
    "        reservations:\n",
    "          devices:\n",
    "            - driver: nvidia\n",
    "              capabilities: [\"gpu\"]\n",
    "              device_ids: [\"0\"]\n",
    "    depends_on:\n",
    "      - \"etcd\"\n",
    "      - \"minio\"\n",
    "\n",
    "networks:\n",
    "  default:\n",
    "    name: milvus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use cmd: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo docker compose up -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We may need to use sudo since we are in /data, and all pip command need to be under sudo.\n",
    "Set the dataset as an environment variableï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "export DATASET=\"cohere\" # or \"openai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip3 install polars\n",
    "pip3 install numpy\n",
    "pip3 install s3fs\n",
    "pip3 install environs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import s3fs\n",
    "import environs\n",
    "env = environs.Env()\n",
    "env.read_env(\".env\")\n",
    "dataset_name = env.str(\"DATASET\", \"cohere\")\n",
    "parquet_path = dataset_name + \"_data/\"\n",
    "npy_path = dataset_name + \"_npy_data/\"\n",
    "\n",
    "base_file = parquet_path + \"shuffle_train.parquet\"\n",
    "query_file = parquet_path + \"test.parquet\"\n",
    "output_base = npy_path + \"base.npy\"\n",
    "output_id = npy_path + \"id.npy\"\n",
    "try: \n",
    "    shutil.rmtree(parquet_path)\n",
    "except:\n",
    "    pass   \n",
    "try:\n",
    "    shutil.rmtree(npy_path)\n",
    "except:\n",
    "    pass\n",
    "os.mkdir(parquet_path)\n",
    "os.mkdir(npy_path)\n",
    "#download s3 file\n",
    "fs = s3fs.S3FileSystem(anon=True, client_kwargs={\"region_name\": \"us-west-2\"})\n",
    "if dataset_name == \"cohere\":\n",
    "    s3_path = \"assets.zilliz.com/benchmark/cohere_medium_1m\"\n",
    "elif dataset_name == \"openai\":\n",
    "    s3_path = \"assets.zilliz.com/benchmark/openai_medium_500k\"\n",
    "dataset_info = fs.ls(s3_path, detail=True)\n",
    "\n",
    "downloads = []\n",
    "for info in dataset_info:\n",
    "    downloads.append(info['Key'])\n",
    "print(\"download files:\", downloads)\n",
    "fs.download(downloads, parquet_path)\n",
    "\n",
    "df_train = pl.read_parquet(base_file)\n",
    "base = np.stack(df_train['emb']).astype(np.float32)\n",
    "id = np.stack(df_train['id']).astype(np.int64)\n",
    "all_embeddings = base / np.linalg.norm(base, axis=1)[:, np.newaxis]\n",
    "np.save(output_base, all_embeddings)\n",
    "np.save(output_id, id)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
